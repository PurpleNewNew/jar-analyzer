{
  "name": "jar-analyzer-workflow",
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        0,
        0
      ],
      "id": "ce3526f7-0110-41b6-bcd1-1feff5316628",
      "name": "Start Workflow"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-globals.globalConstants",
      "typeVersion": 1,
      "position": [
        200,
        0
      ],
      "id": "3c7fd594-8b7f-4871-a2f0-016c19105c31",
      "name": "Global Constants",
      "credentials": {
        "globalConstantsApi": {
          "id": "IH7D2VRyHX4WOTgN",
          "name": "Global Constants account"
        }
      }
    },
    {
      "parameters": {
        "url": "={{ $('Global Constants').first().json.constants['jar-analyzer-api'] }}api/get_jars_list",
        "options": {
          "headers": {
            "Token": "={{ $('Global Constants').first().json.constants['jar-analyzer-api-token'] || '' }}"
          }
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        400,
        0
      ],
      "id": "d24c778f-490d-431f-9833-64a25c6c02af",
      "name": "Get Jars List"
    },
    {
      "parameters": {
        "jsCode": "// Initialize scan config for 5-line audit workflow.\n// Input: /api/get_jars_list response (JSON array of jar paths).\nlet jars = [];\nfor (const it of $input.all()) {\n  const j = it.json;\n  if (Array.isArray(j)) jars.push(...j);\n  else if (Array.isArray(j?.jars)) jars.push(...j.jars);\n  else if (Array.isArray(j?.data)) jars.push(...j.data);\n}\njars = jars.filter(x => typeof x === 'string').map(s => s.trim()).filter(Boolean);\n\n// Heuristic: derive a default gadgetDir from the first jar path\nlet gadgetDir = '';\nif (jars.length > 0) {\n  const first = jars[0];\n  const idx = Math.max(first.lastIndexOf('/'), first.lastIndexOf('\\\\'));\n  if (idx > 0) gadgetDir = first.slice(0, idx);\n}\n\nconst scanConfig = {\n  // Slow line switches\n  enableDfsTaint: false,\n\n  // Line switches\n  enableGraphLite: true,\n  enableVulRules: true,\n  enableScaLeak: true,\n\n  // Scope controls (used by some tools)\n  scope: 'app',         // 'app' or 'all'\n  excludeJdk: true,     // for tools that support excludeJdk\n\n  // Per-line budgets (tune for token/cost vs coverage)\n  limits: {\n    auditFast: {\n      callLimit: 14,\n      mappingSampleLimit: 120,\n      resourceSearchLimit: 80,\n      strSearchPerKeyword: 20,\n      maxCodeConfirm: 6\n    },\n    graphLite: {\n      callLimit: 16,\n      sinkPerTypeLimit: 20,\n      maxDepth: 4,\n      maxChains: 60\n    },\n    vulRules: {\n      callLimit: 10,\n      levels: ['high','medium'],   // run in order\n      groupBy: 'rule',\n      perRuleLimit: 15,\n      totalLimit: 160\n    },\n    scaLeak: {\n      callLimit: 10,\n      enableSca: true,\n      enableLeak: true,\n      enableGadget: false,\n      gadgetDir: gadgetDir,\n      leakLimit: 120\n    },\n    dfsTaint: {\n      callLimit: 28,\n      sinkNames: ['Runtime.exec(String)','ProcessBuilder.start','InitialContext.lookup','URL.openConnection'],\n      depth: 10,\n      maxLimit: 80,\n      maxPaths: 80,\n      timeoutMs: 90000,\n      onlyFromWeb: true,\n      resultLimit: 120,\n      compact: true\n    }\n  }\n};\n\nreturn [{\n  json: {\n    jars,\n    jarCount: jars.length,\n    scanConfig\n  }\n}];\n"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        600,
        0
      ],
      "id": "42bbbfb7-a4af-409c-8a00-7ba32ffbd14b",
      "name": "Init Scan Config"
    },
    {
      "parameters": {
        "model": {
          "__rl": true,
          "value": "glm-4.6",
          "mode": "list",
          "cachedResultName": "GLM-4.6"
        },
        "options": {
          "thinking": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatAnthropic",
      "typeVersion": 1.3,
      "position": [
        600,
        -500
      ],
      "id": "a3399bf1-36d2-49b9-a668-b83c90741058",
      "name": "LLM",
      "credentials": {
        "anthropicApi": {
          "id": "TaNxIU4TnOE9TUHI",
          "name": "Anthropic account"
        }
      }
    },
    {
      "parameters": {
        "sseEndpoint": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-audit-fast'] }}sse",
        "authentication": "headerAuth",
        "headerParameters": {
          "parameters": [
            {
              "name": "Token",
              "value": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-token'] || '' }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolMcp",
      "typeVersion": 1.2,
      "position": [
        800,
        -500
      ],
      "id": "7ffdd714-336f-429b-adf9-c9bf34796857",
      "name": "MCP audit-fast"
    },
    {
      "parameters": {
        "sseEndpoint": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-graph-lite'] }}sse",
        "authentication": "headerAuth",
        "headerParameters": {
          "parameters": [
            {
              "name": "Token",
              "value": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-token'] || '' }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolMcp",
      "typeVersion": 1.2,
      "position": [
        800,
        -430
      ],
      "id": "b35a3194-3527-4983-88cd-18485f4b2593",
      "name": "MCP graph-lite"
    },
    {
      "parameters": {
        "sseEndpoint": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-vul-rules'] }}sse",
        "authentication": "headerAuth",
        "headerParameters": {
          "parameters": [
            {
              "name": "Token",
              "value": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-token'] || '' }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolMcp",
      "typeVersion": 1.2,
      "position": [
        800,
        -360
      ],
      "id": "361552bb-b3f1-4f85-bd5b-d765dbf83413",
      "name": "MCP vul-rules"
    },
    {
      "parameters": {
        "sseEndpoint": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-sca-leak'] }}sse",
        "authentication": "headerAuth",
        "headerParameters": {
          "parameters": [
            {
              "name": "Token",
              "value": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-token'] || '' }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolMcp",
      "typeVersion": 1.2,
      "position": [
        800,
        -290
      ],
      "id": "ef546aca-ef77-4f43-9f04-9dc88e6907b4",
      "name": "MCP sca-leak"
    },
    {
      "parameters": {
        "sseEndpoint": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-dfs-taint'] }}sse",
        "authentication": "headerAuth",
        "headerParameters": {
          "parameters": [
            {
              "name": "Token",
              "value": "={{ $('Global Constants').first().json.constants['jar-analyzer-mcp-token'] || '' }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.toolMcp",
      "typeVersion": 1.2,
      "position": [
        800,
        -220
      ],
      "id": "13b284c6-d201-4c6f-9a7b-ab8d4b238d1b",
      "name": "MCP dfs-taint"
    },
    {
      "parameters": {
        "sseEndpoint": "={{ $('Global Constants').first().json.constants['report-service-mcp'] }}sse",
        "authentication": "headerAuth",
        "headerParameters": {
          "parameters": [
            {
              "name": "Token",
              "value": "={{ $('Global Constants').first().json.constants['report-service-mcp-token'] || '' }}"
            }
          ]
        }
      },
      "type": "@n8n/n8n-nodes-langchain.mcpClientTool",
      "typeVersion": 1.2,
      "position": [
        800,
        420
      ],
      "id": "86bc9dcd-07a8-4332-89ab-9534634c230a",
      "name": "MCP report"
    },
    {
      "parameters": {
        "jsCode": "const cfg = $json.scanConfig || {};\nconst lim = cfg.limits && cfg.limits.auditFast ? cfg.limits.auditFast : {};\nconst callLimit = lim.callLimit || 14;\n\nconst riskyPathHints = [\n  \"/actuator\",\"/swagger\",\"/api-docs\",\"/v2/api-docs\",\"/v3/api-docs\",\n  \"/h2-console\",\"/druid\",\"/jolokia\",\"/admin\",\"/debug\",\"/internal\",\n  \"/management\",\"/metrics\",\"/env\",\"/heapdump\",\"/threaddump\"\n];\n\nconst resourceQueries = [\n  \"management.endpoints\",\"actuator\",\"swagger\",\"api-docs\",\"spring.profiles.active\",\n  \"spring.datasource.password\",\"spring.datasource.username\",\n  \"accessKey\",\"secretKey\",\"AKIA\",\"BEGIN PRIVATE KEY\",\"jwt\",\"token\",\n  \"druid\",\"h2-console\",\"jolokia\",\"log4j2\",\"shiro\",\"rememberMe\",\"xxl.job\"\n];\n\nconst strKeywords = [\n  \"Runtime.getRuntime().exec\",\n  \"new ProcessBuilder\",\n  \"ScriptEngineManager\",\n  \"javax.naming.InitialContext\",\n  \"ObjectInputStream\",\n  \"XMLDecoder\",\n  \"org.yaml.snakeyaml.Yaml\",\n  \"com.alibaba.fastjson\",\n  \"XStream.fromXML\",\n  \"java.net.URL\",\n  \"openConnection(\",\n  \"HttpURLConnection\"\n];\n\nconst mappingSampleLimit = lim.mappingSampleLimit || 120;\nconst resourceSearchLimit = lim.resourceSearchLimit || 80;\nconst strSearchPerKeyword = lim.strSearchPerKeyword || 20;\nconst maxCodeConfirm = lim.maxCodeConfirm || 6;\n\nconst chatInput = `\n你正在执行 **audit-fast**（快线：入口/证据/资源）。仅使用本线 MCP 工具完成扫描，并输出 JSON findings 数组。\n\n执行步骤（务必控制规模）：\n1) 入口盘点（用于证据，不要把“盘点”本身当漏洞输出）：\n   - get_all_spring_controllers\n   - get_all_spring_interceptors\n   - get_all_servlets / get_all_filters / get_all_listeners\n2) Spring Mapping 快筛（只抽样前 ${mappingSampleLimit} 个 controller）：\n   - 对每个 controller 调用 get_spring_mappings(class)\n   - 只保留 path 命中以下敏感前缀的映射：${JSON.stringify(riskyPathHints)}\n   - 对命中的映射输出 findings（type=exposed_endpoint 或 insecure_management_endpoint）\n3) 资源证据快筛：\n   - 对每个 query 调用 search_resources(query, limit=${resourceSearchLimit})\n   - 如果命中配置项表明“管理端点暴露/调试模式/弱配置”，输出 findings（type=insecure_config 或 exposed_admin_surface）\n4) 危险 API 字符串快筛（批量）：\n   - 用 get_methods_by_str_batch(items=[{str,limit}...], limit=${strSearchPerKeyword}) 搜索：${JSON.stringify(strKeywords)}\n   - 对命中 count>0 的条目，挑选最可疑的方法（总计不超过 ${maxCodeConfirm} 个）用 get_code_cfr 获取片段确认\n   - 依据证据输出 findings（type=risky_api_usage / potential_rce_surface / potential_ssrf_surface / potential_deserialization）\n输出要求：\n- findings 中每条都要有 trace（至少 1 个方法：命中的 handler 或命中的方法）\n- 不要输出大段源码全文，只在 reason/evidence 中引用极短片段或关键调用点\n- 无发现输出 []\n`;\nreturn [{ json: { ...$json, line: \"audit-fast\", callLimit, chatInput } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        800,
        -300
      ],
      "id": "adb464b5-47c8-4609-9575-046717e3c3d9",
      "name": "Build Prompt audit-fast"
    },
    {
      "parameters": {
        "jsCode": "const cfg = $json.scanConfig || {};\nconst lim = cfg.limits && cfg.limits.graphLite ? cfg.limits.graphLite : {};\nconst callLimit = lim.callLimit || 16;\n\nconst sinkNames = [\n  \"Runtime.exec(String)\",\n  \"ProcessBuilder.start\",\n  \"ScriptEngine.eval\",\n  \"InitialContext.lookup\",\n  \"Context.lookup\",\n  \"DirContext.search\",\n  \"LdapContext.search\",\n  \"Statement.executeQuery\",\n  \"Statement.executeUpdate\",\n  \"Connection.prepareStatement\",\n  \"ObjectInputStream.readObject\",\n  \"XMLDecoder.readObject\",\n  \"Yaml.load\",\n  \"JSON.parseObject\",\n  \"ObjectMapper.readValue\",\n  \"HessianInput.readObject\",\n  \"XStream.fromXML\",\n  \"URL.openConnection\",\n  \"HttpURLConnection.connect\",\n  \"FileInputStream.new\",\n  \"FileOutputStream.new\",\n  \"RandomAccessFile.new\",\n  \"File.delete\"\n];\n\nconst sinkPerTypeLimit = lim.sinkPerTypeLimit || 20;\nconst maxDepth = lim.maxDepth || 4;\nconst maxChains = lim.maxChains || 60;\n\nconst chatInput = `\n你正在执行 **graph-lite**（快线：调用图/方法索引，轻量回溯）。\n目标：从常见 Sink 出发，使用调用图向上回溯若干层，构造“潜在可达链路”，输出 JSON findings。\n\n执行策略（务必限流，避免爆炸）：\n1) 对以下 sinkName 逐个调用 get_callers_by_sink(sinkName, limit=${sinkPerTypeLimit})：\n   ${JSON.stringify(sinkNames)}\n2) 对每个 sink 的每个调用点（MethodResult）：\n   - 以该方法为起点，最多回溯 ${maxDepth} 层：\n     使用 get_callers(class, method, desc) 找上游调用者\n   - 每层最多保留 2~3 个最像业务代码的 caller（优先包名非 java/javax/sun，且类名包含 Controller/Service/Action/Servlet/Handler）\n   - 一旦发现疑似入口（例如方法名 doGet/doPost/service，或类名包含 Controller/Servlet），可提前停止\n3) 对每条链路输出 1 个 finding（最多 ${maxChains} 条）：\n   - type：根据 sinkName 粗略归类（command_exec/sql_injection/jndi_injection/deserialization/ssrf/file_io 等）\n   - confidence：如果链路起点疑似入口则 medium/high；否则 low/medium\n   - trace：从“疑似入口”到“调用点”再到“sink”三段（若无法确认入口，则 trace 以 callers 链 + sink 结束）\n注意：\n- 这是 graph-lite：只做“调用可达”粗回溯，不做参数污染确认，所以 reason 要明确“仅调用图可达，需 dfs/taint 复核”。\n- 无发现输出 []\n`;\nreturn [{ json: { ...$json, line: \"graph-lite\", callLimit, chatInput } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        800,
        -150
      ],
      "id": "aba8461e-a80c-4f24-a884-371dad03097e",
      "name": "Build Prompt graph-lite"
    },
    {
      "parameters": {
        "jsCode": "const cfg = $json.scanConfig || {};\nconst lim = cfg.limits && cfg.limits.vulRules ? cfg.limits.vulRules : {};\nconst callLimit = lim.callLimit || 10;\n\nconst levels = Array.isArray(lim.levels) && lim.levels.length ? lim.levels : [\"high\"];\nconst perRuleLimit = lim.perRuleLimit || 15;\nconst totalLimit = lim.totalLimit || 160;\nconst groupBy = lim.groupBy || \"rule\";\n\nconst chatInput = `\n你正在执行 **vul-rules**（规则线）。\n目标：使用 vulnerability.yaml 规则在全局搜索调用点，并将命中转换为 JSON findings。\n\n执行步骤（按 levels 顺序，务必控量）：\n1) 可选：get_vul_rules 获取规则概览（用于了解可用 rule 名称）\n2) 对每个 level ∈ ${JSON.stringify(levels)}：\n   - 调用 vul_search(level=level, groupBy=\"rule\", totalLimit=${totalLimit}, limit=${perRuleLimit})\n   - 对命中 count>0 的规则（优先 high 命中多的）：\n     再调用 vul_search(name=ruleName, level=level, groupBy=\"method\", totalLimit=${totalLimit}, limit=${perRuleLimit})\n3) 将每个 MethodResult 命中点输出为 finding：\n   - line=\"vul-rules\"\n   - type：可直接用 \"vul-rule::<ruleName>\"（也可以映射为更具体类型）\n   - severity：来自 rule 的 level（high/medium/low）\n   - confidence：medium（规则命中是调用点，仍需结合入口/参数判定可利用性）\n   - trace：至少包含命中方法（class/method/desc）；若结果中带 actualPath/restfulType/jarName，可放入 evidence\n注意：\n- 不要输出重复项（同一 class#method#desc + 同一 ruleName 只输出一次）\n- 无发现输出 []\n`;\nreturn [{ json: { ...$json, line: \"vul-rules\", callLimit, chatInput } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        800,
        0
      ],
      "id": "7951e52f-23d7-4d75-af20-2d0f9b1f1ed7",
      "name": "Build Prompt vul-rules"
    },
    {
      "parameters": {
        "jsCode": "const cfg = $json.scanConfig || {};\nconst lim = cfg.limits && cfg.limits.scaLeak ? cfg.limits.scaLeak : {};\nconst callLimit = lim.callLimit || 10;\n\nconst enableSca = lim.enableSca !== false;\nconst enableLeak = lim.enableLeak !== false;\nconst enableGadget = lim.enableGadget === true;\nconst gadgetDir = lim.gadgetDir || '';\nconst leakLimit = lim.leakLimit || 120;\n\nconst chatInput = `\n你正在执行 **sca-leak**（依赖/泄露线）。\n目标：执行 SCA 漏洞依赖扫描 + 泄露扫描（可选 gadget 扫描），输出 JSON findings。\n\n执行步骤：\n1) ${enableSca ? \"调用 sca_scan(log4j=1, fastjson=1, shiro=1) 获取依赖漏洞命中（CVE/cvss/jarPath/project/version）。\" : \"跳过 sca_scan（enableSca=false）。\"}\n2) ${enableLeak ? `调用 leak_scan(limit=${leakLimit}, scope=\"${cfg.scope||'app'}\") 获取泄露（typeName/value/className/jarName）。` : \"跳过 leak_scan（enableLeak=false）。\"}\n3) ${enableGadget ? `调用 gadget_scan(dir=\"${gadgetDir}\", native=1, hessian=1, fastjson=1, jdbc=1) 获取 gadget 依赖链命中。` : \"gadget_scan 默认关闭（enableGadget=false 或 gadgetDir 为空）。\"}\n\n输出规范：\n- SCA 命中：type=\"dependency_cve\"，severity 按 cvss（>=9 high, >=7 medium, else low），confidence=high\n- 泄露命中：type=\"secret_leak\"，severity=high，confidence=high（reason 需包含 typeName 与脱敏 value 片段）\n- gadget 命中：type=\"gadget_presence\" 或 \"deserialization_gadget\"，severity=medium/high，confidence=medium/high\n- trace：至少包含 1 个点；对于 SCA 可用 jarPath 作为 trace 的 desc（class/method 可留空但必须给字段）；对于 leak 可用 className 作为 class\n注意：\n- 输出 value 时务必脱敏：只保留前 4 + 后 4（中间用 ***）\n- 无发现输出 []\n`;\nreturn [{ json: { ...$json, line: \"sca-leak\", callLimit, chatInput } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        800,
        150
      ],
      "id": "163ea303-0132-4c63-826a-922f05925857",
      "name": "Build Prompt sca-leak"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.scanConfig.enableDfsTaint }}",
              "operation": "isTrue"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        800,
        300
      ],
      "id": "6992d98c-54b1-4a35-bb0a-acffa3a75f4a",
      "name": "If Enable dfs-taint"
    },
    {
      "parameters": {
        "jsCode": "const cfg = $json.scanConfig || {};\nconst lim = cfg.limits && cfg.limits.dfsTaint ? cfg.limits.dfsTaint : {};\nconst callLimit = lim.callLimit || 28;\n\nconst sinkNames = Array.isArray(lim.sinkNames) && lim.sinkNames.length ? lim.sinkNames : [\"Runtime.exec(String)\"];\nconst depth = lim.depth || 10;\nconst maxLimit = lim.maxLimit || 80;\nconst maxPaths = lim.maxPaths || 80;\nconst timeoutMs = lim.timeoutMs || 90000;\nconst onlyFromWeb = lim.onlyFromWeb !== false;\nconst resultLimit = lim.resultLimit || 120;\nconst compact = lim.compact !== false;\n\nconst chatInput = `\n你正在执行 **dfs-taint**（慢线：DFS/污点链路）。这是可选慢线，可能耗时。\n目标：对关键 sink 触发 DFS 搜索所有可达 source（尽量 onlyFromWeb），拿到链路并输出 findings。\n\n执行步骤（务必控量）：\n1) 对 sinkName ∈ ${JSON.stringify(sinkNames)} 逐个调用：\n   - get_dfs_chains(mode=\"sink\", sinkName=sinkName, searchAllSources=true, depth=${depth}, maxLimit=${maxLimit}, maxPaths=${maxPaths}, timeoutMs=${timeoutMs}, onlyFromWeb=${onlyFromWeb})\n   记录返回的 jobId\n2) 对每个 jobId：\n   - 轮询 get_dfs_job(jobId) 直到 status 为 finished/done 或 error（必要时少量重试）\n   - 完成后调用 get_dfs_results(jobId, limit=${resultLimit}, offset=0, compact=${compact})\n3) 将每条 DFSResult 转换为 finding：\n   - type：基于 sinkName 分类（command_exec/sql/jndi/deserialization/ssrf/file_io 等）\n   - severity：通常 high（链路可达）\n   - confidence：high/medium（onlyFromWeb=true 则更高）\n   - trace：使用 results.items[].methods（compact=true 时字段可能是 methods），从 source 到 sink 的方法序列\n注意：\n- 如果 job 结果为空或被 truncated，也可输出 1 条低置信度 findings，reason 说明 truncated/recommend\n- 无发现输出 []\n`;\nreturn [{ json: { ...$json, line: \"dfs-taint\", callLimit, chatInput } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1000,
        240
      ],
      "id": "af9a79e3-78b8-43ea-b551-ff9ee0319df0",
      "name": "Build Prompt dfs-taint"
    },
    {
      "parameters": {
        "jsCode": "// DFS slow line disabled: return empty findings placeholder so merge can proceed.\nreturn [{\n  json: {\n    line: \"dfs-taint\",\n    parseOk: true,\n    parseError: \"disabled\",\n    findings: []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1000,
        360
      ],
      "id": "a4532deb-5c9a-48fb-aef8-1ac916f6a04d",
      "name": "DFS Disabled"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "你是资深 Java 安全审计工程师，目标是做自动化安全审计（静态分析）。\n必须遵守：\n1) 只能使用当前可用的 MCP 工具获取事实证据；禁止凭空猜测。\n2) 严格控制输出规模：优先使用批量/limit/compact/totalLimit 参数。\n3) 只输出 JSON 数组（不要输出解释、不要 Markdown、不要代码块围栏）。没有发现则输出 []。\n4) findings 数组元素必须包含字段：\n   - line (string)\n   - type (string)\n   - severity (\"high\"|\"medium\"|\"low\")\n   - confidence (\"high\"|\"medium\"|\"low\")\n   - score (1-10 整数)\n   - reason (string, 简洁说明命中原因与证据点)\n   - trace (array, 每项包含 {\"class\",\"method\",\"desc\"}；desc 可为空字符串)\n可以附加 evidence/metadata 等字段，但不要输出大段源码全文。",
          "maxIterations": "={{ $json.callLimit }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1000,
        -300
      ],
      "id": "5d86c784-bd92-4367-89ff-fd1debba163f",
      "name": "Agent audit-fast",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "你是资深 Java 安全审计工程师，目标是做自动化安全审计（静态分析）。\n必须遵守：\n1) 只能使用当前可用的 MCP 工具获取事实证据；禁止凭空猜测。\n2) 严格控制输出规模：优先使用批量/limit/compact/totalLimit 参数。\n3) 只输出 JSON 数组（不要输出解释、不要 Markdown、不要代码块围栏）。没有发现则输出 []。\n4) findings 数组元素必须包含字段：\n   - line (string)\n   - type (string)\n   - severity (\"high\"|\"medium\"|\"low\")\n   - confidence (\"high\"|\"medium\"|\"low\")\n   - score (1-10 整数)\n   - reason (string, 简洁说明命中原因与证据点)\n   - trace (array, 每项包含 {\"class\",\"method\",\"desc\"}；desc 可为空字符串)\n可以附加 evidence/metadata 等字段，但不要输出大段源码全文。",
          "maxIterations": "={{ $json.callLimit }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1000,
        -150
      ],
      "id": "ffeb8ab4-9cc6-4ace-9a58-4c599505a289",
      "name": "Agent graph-lite",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "你是资深 Java 安全审计工程师，目标是做自动化安全审计（静态分析）。\n必须遵守：\n1) 只能使用当前可用的 MCP 工具获取事实证据；禁止凭空猜测。\n2) 严格控制输出规模：优先使用批量/limit/compact/totalLimit 参数。\n3) 只输出 JSON 数组（不要输出解释、不要 Markdown、不要代码块围栏）。没有发现则输出 []。\n4) findings 数组元素必须包含字段：\n   - line (string)\n   - type (string)\n   - severity (\"high\"|\"medium\"|\"low\")\n   - confidence (\"high\"|\"medium\"|\"low\")\n   - score (1-10 整数)\n   - reason (string, 简洁说明命中原因与证据点)\n   - trace (array, 每项包含 {\"class\",\"method\",\"desc\"}；desc 可为空字符串)\n可以附加 evidence/metadata 等字段，但不要输出大段源码全文。",
          "maxIterations": "={{ $json.callLimit }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1000,
        0
      ],
      "id": "07a11561-f4be-4cbd-badd-99d52c36d90c",
      "name": "Agent vul-rules",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "你是资深 Java 安全审计工程师，目标是做自动化安全审计（静态分析）。\n必须遵守：\n1) 只能使用当前可用的 MCP 工具获取事实证据；禁止凭空猜测。\n2) 严格控制输出规模：优先使用批量/limit/compact/totalLimit 参数。\n3) 只输出 JSON 数组（不要输出解释、不要 Markdown、不要代码块围栏）。没有发现则输出 []。\n4) findings 数组元素必须包含字段：\n   - line (string)\n   - type (string)\n   - severity (\"high\"|\"medium\"|\"low\")\n   - confidence (\"high\"|\"medium\"|\"low\")\n   - score (1-10 整数)\n   - reason (string, 简洁说明命中原因与证据点)\n   - trace (array, 每项包含 {\"class\",\"method\",\"desc\"}；desc 可为空字符串)\n可以附加 evidence/metadata 等字段，但不要输出大段源码全文。",
          "maxIterations": "={{ $json.callLimit }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1000,
        150
      ],
      "id": "ed643ced-b87e-488b-9c84-3d4012471fad",
      "name": "Agent sca-leak",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "你是资深 Java 安全审计工程师，目标是做自动化安全审计（静态分析）。\n必须遵守：\n1) 只能使用当前可用的 MCP 工具获取事实证据；禁止凭空猜测。\n2) 严格控制输出规模：优先使用批量/limit/compact/totalLimit 参数。\n3) 只输出 JSON 数组（不要输出解释、不要 Markdown、不要代码块围栏）。没有发现则输出 []。\n4) findings 数组元素必须包含字段：\n   - line (string)\n   - type (string)\n   - severity (\"high\"|\"medium\"|\"low\")\n   - confidence (\"high\"|\"medium\"|\"low\")\n   - score (1-10 整数)\n   - reason (string, 简洁说明命中原因与证据点)\n   - trace (array, 每项包含 {\"class\",\"method\",\"desc\"}；desc 可为空字符串)\n可以附加 evidence/metadata 等字段，但不要输出大段源码全文。",
          "maxIterations": "={{ $json.callLimit }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        1200,
        240
      ],
      "id": "68ff9d53-62c3-4997-b9ec-1850934aa34a",
      "name": "Agent dfs-taint",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "// Parse AI Agent output into {line, findings[]}.\n// Accepts:\n// - Raw JSON array\n// - Object with {findings:[...]} or {data:[...]} etc\n// - Markdown ```json ... ```\nconst ctx = $json || {};\nconst line = ctx.line || (ctx.context && ctx.context.line) || \"unknown\";\n\nfunction extractText(v) {\n  if (v === null || v === undefined) return \"\";\n  if (typeof v === \"string\") return v;\n  try { return JSON.stringify(v); } catch (e) { return String(v); }\n}\n\nlet raw = ctx.output ?? ctx.text ?? ctx.data ?? ctx;\nlet s = extractText(raw).trim();\n\n// Strip markdown fences if present\nconst fence = s.match(/```json\\s*([\\s\\S]*?)```/i);\nif (fence && fence[1]) s = fence[1].trim();\n\nlet findings = [];\nlet parseOk = false;\nlet parseError = \"\";\n\nif (!s) {\n  parseError = \"empty_response\";\n} else {\n  try {\n    const obj = JSON.parse(s);\n    if (Array.isArray(obj)) {\n      findings = obj;\n      parseOk = true;\n    } else if (obj && typeof obj === \"object\") {\n      if (Array.isArray(obj.findings)) {\n        findings = obj.findings;\n        parseOk = true;\n      } else if (Array.isArray(obj.data)) {\n        findings = obj.data;\n        parseOk = true;\n      } else {\n        parseError = \"json_object_without_findings_array\";\n      }\n    } else {\n      parseError = \"json_not_array\";\n    }\n  } catch (e) {\n    parseError = e.message || String(e);\n  }\n}\n\nif (!parseOk) {\n  throw new Error(`[${line}] parse failed: ${parseError}`);\n}\n\nreturn [{\n  json: {\n    line,\n    parseOk,\n    parseError,\n    findings: Array.isArray(findings) ? findings : []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1200,
        -300
      ],
      "id": "4d4a8d87-0f45-4514-bb09-7ed2ffb11d1b",
      "name": "Parse audit-fast"
    },
    {
      "parameters": {
        "jsCode": "// Parse AI Agent output into {line, findings[]}.\n// Accepts:\n// - Raw JSON array\n// - Object with {findings:[...]} or {data:[...]} etc\n// - Markdown ```json ... ```\nconst ctx = $json || {};\nconst line = ctx.line || (ctx.context && ctx.context.line) || \"unknown\";\n\nfunction extractText(v) {\n  if (v === null || v === undefined) return \"\";\n  if (typeof v === \"string\") return v;\n  try { return JSON.stringify(v); } catch (e) { return String(v); }\n}\n\nlet raw = ctx.output ?? ctx.text ?? ctx.data ?? ctx;\nlet s = extractText(raw).trim();\n\n// Strip markdown fences if present\nconst fence = s.match(/```json\\s*([\\s\\S]*?)```/i);\nif (fence && fence[1]) s = fence[1].trim();\n\nlet findings = [];\nlet parseOk = false;\nlet parseError = \"\";\n\nif (!s) {\n  parseError = \"empty_response\";\n} else {\n  try {\n    const obj = JSON.parse(s);\n    if (Array.isArray(obj)) {\n      findings = obj;\n      parseOk = true;\n    } else if (obj && typeof obj === \"object\") {\n      if (Array.isArray(obj.findings)) {\n        findings = obj.findings;\n        parseOk = true;\n      } else if (Array.isArray(obj.data)) {\n        findings = obj.data;\n        parseOk = true;\n      } else {\n        parseError = \"json_object_without_findings_array\";\n      }\n    } else {\n      parseError = \"json_not_array\";\n    }\n  } catch (e) {\n    parseError = e.message || String(e);\n  }\n}\n\nif (!parseOk) {\n  throw new Error(`[${line}] parse failed: ${parseError}`);\n}\n\nreturn [{\n  json: {\n    line,\n    parseOk,\n    parseError,\n    findings: Array.isArray(findings) ? findings : []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1200,
        -150
      ],
      "id": "ad630b4d-68d5-4663-b93e-8944de0d5e9b",
      "name": "Parse graph-lite"
    },
    {
      "parameters": {
        "jsCode": "// Parse AI Agent output into {line, findings[]}.\n// Accepts:\n// - Raw JSON array\n// - Object with {findings:[...]} or {data:[...]} etc\n// - Markdown ```json ... ```\nconst ctx = $json || {};\nconst line = ctx.line || (ctx.context && ctx.context.line) || \"unknown\";\n\nfunction extractText(v) {\n  if (v === null || v === undefined) return \"\";\n  if (typeof v === \"string\") return v;\n  try { return JSON.stringify(v); } catch (e) { return String(v); }\n}\n\nlet raw = ctx.output ?? ctx.text ?? ctx.data ?? ctx;\nlet s = extractText(raw).trim();\n\n// Strip markdown fences if present\nconst fence = s.match(/```json\\s*([\\s\\S]*?)```/i);\nif (fence && fence[1]) s = fence[1].trim();\n\nlet findings = [];\nlet parseOk = false;\nlet parseError = \"\";\n\nif (!s) {\n  parseError = \"empty_response\";\n} else {\n  try {\n    const obj = JSON.parse(s);\n    if (Array.isArray(obj)) {\n      findings = obj;\n      parseOk = true;\n    } else if (obj && typeof obj === \"object\") {\n      if (Array.isArray(obj.findings)) {\n        findings = obj.findings;\n        parseOk = true;\n      } else if (Array.isArray(obj.data)) {\n        findings = obj.data;\n        parseOk = true;\n      } else {\n        parseError = \"json_object_without_findings_array\";\n      }\n    } else {\n      parseError = \"json_not_array\";\n    }\n  } catch (e) {\n    parseError = e.message || String(e);\n  }\n}\n\nif (!parseOk) {\n  throw new Error(`[${line}] parse failed: ${parseError}`);\n}\n\nreturn [{\n  json: {\n    line,\n    parseOk,\n    parseError,\n    findings: Array.isArray(findings) ? findings : []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1200,
        0
      ],
      "id": "75b2a433-653c-4469-a462-107cd6f6aeb6",
      "name": "Parse vul-rules"
    },
    {
      "parameters": {
        "jsCode": "// Parse AI Agent output into {line, findings[]}.\n// Accepts:\n// - Raw JSON array\n// - Object with {findings:[...]} or {data:[...]} etc\n// - Markdown ```json ... ```\nconst ctx = $json || {};\nconst line = ctx.line || (ctx.context && ctx.context.line) || \"unknown\";\n\nfunction extractText(v) {\n  if (v === null || v === undefined) return \"\";\n  if (typeof v === \"string\") return v;\n  try { return JSON.stringify(v); } catch (e) { return String(v); }\n}\n\nlet raw = ctx.output ?? ctx.text ?? ctx.data ?? ctx;\nlet s = extractText(raw).trim();\n\n// Strip markdown fences if present\nconst fence = s.match(/```json\\s*([\\s\\S]*?)```/i);\nif (fence && fence[1]) s = fence[1].trim();\n\nlet findings = [];\nlet parseOk = false;\nlet parseError = \"\";\n\nif (!s) {\n  parseError = \"empty_response\";\n} else {\n  try {\n    const obj = JSON.parse(s);\n    if (Array.isArray(obj)) {\n      findings = obj;\n      parseOk = true;\n    } else if (obj && typeof obj === \"object\") {\n      if (Array.isArray(obj.findings)) {\n        findings = obj.findings;\n        parseOk = true;\n      } else if (Array.isArray(obj.data)) {\n        findings = obj.data;\n        parseOk = true;\n      } else {\n        parseError = \"json_object_without_findings_array\";\n      }\n    } else {\n      parseError = \"json_not_array\";\n    }\n  } catch (e) {\n    parseError = e.message || String(e);\n  }\n}\n\nif (!parseOk) {\n  throw new Error(`[${line}] parse failed: ${parseError}`);\n}\n\nreturn [{\n  json: {\n    line,\n    parseOk,\n    parseError,\n    findings: Array.isArray(findings) ? findings : []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1200,
        150
      ],
      "id": "c062fbc9-4270-4cd2-9cd7-41d2beec0894",
      "name": "Parse sca-leak"
    },
    {
      "parameters": {
        "jsCode": "// Parse AI Agent output into {line, findings[]}.\n// Accepts:\n// - Raw JSON array\n// - Object with {findings:[...]} or {data:[...]} etc\n// - Markdown ```json ... ```\nconst ctx = $json || {};\nconst line = ctx.line || (ctx.context && ctx.context.line) || \"unknown\";\n\nfunction extractText(v) {\n  if (v === null || v === undefined) return \"\";\n  if (typeof v === \"string\") return v;\n  try { return JSON.stringify(v); } catch (e) { return String(v); }\n}\n\nlet raw = ctx.output ?? ctx.text ?? ctx.data ?? ctx;\nlet s = extractText(raw).trim();\n\n// Strip markdown fences if present\nconst fence = s.match(/```json\\s*([\\s\\S]*?)```/i);\nif (fence && fence[1]) s = fence[1].trim();\n\nlet findings = [];\nlet parseOk = false;\nlet parseError = \"\";\n\nif (!s) {\n  parseError = \"empty_response\";\n} else {\n  try {\n    const obj = JSON.parse(s);\n    if (Array.isArray(obj)) {\n      findings = obj;\n      parseOk = true;\n    } else if (obj && typeof obj === \"object\") {\n      if (Array.isArray(obj.findings)) {\n        findings = obj.findings;\n        parseOk = true;\n      } else if (Array.isArray(obj.data)) {\n        findings = obj.data;\n        parseOk = true;\n      } else {\n        parseError = \"json_object_without_findings_array\";\n      }\n    } else {\n      parseError = \"json_not_array\";\n    }\n  } catch (e) {\n    parseError = e.message || String(e);\n  }\n}\n\nif (!parseOk) {\n  throw new Error(`[${line}] parse failed: ${parseError}`);\n}\n\nreturn [{\n  json: {\n    line,\n    parseOk,\n    parseError,\n    findings: Array.isArray(findings) ? findings : []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1400,
        240
      ],
      "id": "52ea6453-7cb0-421e-839f-6e9e7359f861",
      "name": "Parse dfs-taint"
    },
    {
      "parameters": {
        "numberInputs": 5
      },
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3.2,
      "position": [
        1400,
        0
      ],
      "id": "d9fd97e3-6aaa-4b11-b2cd-17c9fff98523",
      "name": "Merge Lines"
    },
    {
      "parameters": {
        "jsCode": "// Collect findings from 5 lines, normalize schema, de-duplicate, and output one item per unique finding.\nconst inputs = $input.all();\n\nconst allowedSev = new Set(['high','medium','low']);\nconst allowedConf = new Set(['high','medium','low']);\n\nfunction normStr(v) {\n  if (v === null || v === undefined) return '';\n  return String(v);\n}\n\nfunction normLevel(v, defVal) {\n  const s = normStr(v).trim().toLowerCase();\n  if (allowedSev.has(s)) return s;\n  if (allowedConf.has(s)) return s;\n  return defVal;\n}\n\nfunction normalizeClassName(c) {\n  const s = normStr(c).trim();\n  if (!s) return '';\n  return s.replace(/\\//g, '.');\n}\n\nfunction normalizeTrace(trace, fallback) {\n  let t = [];\n  if (Array.isArray(trace)) {\n    t = trace.map(x => {\n      const o = (x && typeof x === 'object') ? x : {};\n      return {\n        class: normalizeClassName(o.class || o.className || o.cls || ''),\n        method: normStr(o.method || o.methodName || '').trim(),\n        desc: normStr(o.desc || o.methodDesc || '').trim(),\n      };\n    }).filter(x => x.class || x.method || x.desc);\n  }\n  if (!t.length && fallback) {\n    t = [fallback].filter(x => x.class || x.method || x.desc);\n  }\n  if (!t.length) t = [{class:'', method:'', desc:''}];\n  return t;\n}\n\nfunction clampInt(n, min, max) {\n  const x = parseInt(n, 10);\n  if (Number.isNaN(x)) return null;\n  return Math.min(max, Math.max(min, x));\n}\n\nfunction scoreBy(sev, conf) {\n  const s = sev || 'low';\n  const c = conf || 'low';\n  const table = {\n    'high':   {'high':9, 'medium':8, 'low':7},\n    'medium': {'high':7, 'medium':6, 'low':5},\n    'low':    {'high':4, 'medium':3, 'low':2},\n  };\n  return table[s]?.[c] ?? 3;\n}\n\nfunction maskSecret(v) {\n  const s = normStr(v).trim();\n  if (s.length <= 8) return s ? (s[0] + '***') : '';\n  return s.slice(0,4) + '***' + s.slice(-4);\n}\n\n// Map some common vul-rule names / sink names into canonical types (optional)\nfunction canonicalType(line, type, f) {\n  const t = normStr(type).trim();\n  const ruleName = normStr(f.ruleName || f.rule || f.name || '').trim();\n  const sinkName = normStr(f.sinkName || f.sink || '').trim();\n\n  // If already namespace'd\n  if (t.startsWith('vul-rule::')) return t;\n\n  if (line === 'vul-rules') {\n    if (ruleName) return `vul-rule::${ruleName}`;\n    if (t) return `vul-rule::${t}`;\n  }\n\n  // dfs/graph sinkName based\n  const sname = sinkName || t;\n  if (/Runtime\\.exec/i.test(sname) || /ProcessBuilder/i.test(sname)) return 'command_execution';\n  if (/InitialContext\\.lookup/i.test(sname) || /Context\\.lookup/i.test(sname) || /DirContext\\.search/i.test(sname) || /LdapContext\\.search/i.test(sname)) return 'jndi_injection';\n  if (/Statement\\.execute|executeQuery|executeUpdate|prepareStatement/i.test(sname)) return 'sql_injection';\n  if (/ObjectInputStream\\.readObject|XMLDecoder\\.readObject|Hessian.*readObject|XStream\\.fromXML|Yaml\\.load|JSON\\.parseObject|ObjectMapper\\.readValue/i.test(sname)) return 'insecure_deserialization';\n  if (/URL\\.openConnection|HttpURLConnection\\.connect/i.test(sname)) return 'ssrf';\n  if (/File(Input|Output)Stream\\.new|RandomAccessFile\\.new|File\\.delete/i.test(sname)) return 'file_io';\n\n  if (line === 'sca-leak') {\n    if (t === 'secret_leak') return 'secret_leak';\n    if (t === 'dependency_cve') return 'dependency_cve';\n    if (t === 'gadget_presence' || t === 'deserialization_gadget') return t;\n  }\n\n  if (t) return t;\n  return 'unknown';\n}\n\nfunction normalizeFinding(line, f) {\n  const obj = (f && typeof f === 'object') ? f : {};\n  const out = {};\n\n  out.line = normStr(obj.line || line || 'unknown').trim() || 'unknown';\n\n  // type / ruleName / sinkName\n  out.ruleName = normStr(obj.ruleName || obj.rule || obj.name || '').trim() || undefined;\n  out.sinkName = normStr(obj.sinkName || obj.sink || '').trim() || undefined;\n  out.type = canonicalType(out.line, obj.type, { ...obj, ruleName: out.ruleName, sinkName: out.sinkName });\n\n  // severity/confidence\n  // For some known types we can force defaults\n  let sev = normLevel(obj.severity, 'low');\n  let conf = normLevel(obj.confidence, 'low');\n\n  if (out.type === 'secret_leak') {\n    sev = 'high'; conf = 'high';\n  }\n\n  // SCA CVE: compute sev by cvss if available\n  const cvss = obj.cvss ?? (obj.evidence && obj.evidence.cvss);\n  const cvssNum = typeof cvss === 'number' ? cvss : parseFloat(cvss);\n  if (out.type === 'dependency_cve' && !Number.isNaN(cvssNum)) {\n    if (cvssNum >= 9.0) sev = 'high';\n    else if (cvssNum >= 7.0) sev = 'medium';\n    else sev = 'low';\n    conf = 'high';\n  }\n\n  out.severity = allowedSev.has(sev) ? sev : 'low';\n  out.confidence = allowedConf.has(conf) ? conf : 'low';\n\n  // score\n  let score = clampInt(obj.score, 1, 10);\n  if (score === null) {\n    // for CVE, map cvss to 1..10\n    if (out.type === 'dependency_cve' && !Number.isNaN(cvssNum)) {\n      score = Math.max(1, Math.min(10, Math.round(cvssNum)));\n    } else {\n      score = scoreBy(out.severity, out.confidence);\n    }\n  }\n  out.score = score;\n\n  // trace\n  const fallback = {\n    class: normalizeClassName(obj.className || obj.class || ''),\n    method: normStr(obj.methodName || obj.method || '').trim(),\n    desc: normStr(obj.methodDesc || obj.desc || '').trim(),\n  };\n  out.trace = normalizeTrace(obj.trace, fallback);\n\n  // reason (keep short)\n  let reason = normStr(obj.reason || '').trim();\n  if (!reason) {\n    if (out.type === 'secret_leak') {\n      const tn = normStr(obj.typeName || (obj.evidence && obj.evidence.typeName) || '').trim();\n      const val = maskSecret(obj.value || (obj.evidence && obj.evidence.value));\n      reason = `Potential secret leak (${tn}) value=${val}`;\n    } else if (out.type === 'dependency_cve') {\n      const cve = normStr(obj.cve || (obj.evidence && obj.evidence.cve) || '').trim();\n      const proj = normStr(obj.project || (obj.evidence && obj.evidence.project) || '').trim();\n      const ver = normStr(obj.version || (obj.evidence && obj.evidence.version) || '').trim();\n      reason = `Dependency vulnerability ${cve} ${proj} ${ver}`.trim();\n    } else if (out.type.startsWith('vul-rule::')) {\n      reason = `Rule hit: ${out.type}`;\n    } else {\n      reason = `${out.type} hit`;\n    }\n  }\n  if (reason.length > 500) reason = reason.slice(0, 500) + '...';\n  out.reason = reason;\n\n  // evidence (keep small)\n  if (obj.evidence && typeof obj.evidence === 'object') {\n    out.evidence = obj.evidence;\n  } else {\n    const ev = {};\n    // common fields\n    for (const k of ['jarName','jarPath','actualPath','restfulType','path','value','typeName','cve','cvss','project','version','matchedJarNames','matchedJarPaths']) {\n      if (obj[k] !== undefined && obj[k] !== null && normStr(obj[k]).trim() !== '') ev[k] = obj[k];\n    }\n    if (Object.keys(ev).length) out.evidence = ev;\n  }\n\n  return out;\n}\n\nfunction dedupKey(f) {\n  const t0 = f.trace && f.trace.length ? f.trace[0] : {class:'', method:'', desc:''};\n  const anchor = `${t0.class}#${t0.method}${t0.desc ? ':'+t0.desc : ''}`;\n  const extra = f.ruleName ? `|rule=${f.ruleName}` : (f.sinkName ? `|sink=${f.sinkName}` : '');\n  // For secret leak, include typeName + masked value to reduce duplicates\n  if (f.type === 'secret_leak') {\n    const tn = normStr(f.evidence && f.evidence.typeName || '');\n    const val = maskSecret(f.evidence && f.evidence.value || '');\n    return `${f.type}|${tn}|${val}|${anchor}`;\n  }\n  // For dependency CVE, include CVE + jarPath\n  if (f.type === 'dependency_cve') {\n    const cve = normStr(f.evidence && f.evidence.cve || '');\n    const jar = normStr(f.evidence && f.evidence.jarPath || f.evidence && f.evidence.jarName || '');\n    return `${f.type}|${cve}|${jar}|${anchor}`;\n  }\n  return `${f.type}|${anchor}${extra}`;\n}\n\nfunction rank(f) {\n  const cw = {high:3, medium:2, low:1};\n  return (cw[f.confidence] || 1) * 100 + (cw[f.severity] || 1) * 10 + (f.score || 0);\n}\n\n// Collect all findings\nconst all = [];\nfor (const it of inputs) {\n  const line = it.json && it.json.line ? it.json.line : 'unknown';\n  const arr = Array.isArray(it.json && it.json.findings) ? it.json.findings : [];\n  for (const f of arr) {\n    all.push({ line, f });\n  }\n}\n\n// Normalize + dedup\nconst best = new Map();\nfor (const {line, f} of all) {\n  const nf = normalizeFinding(line, f);\n  const key = dedupKey(nf);\n  const prev = best.get(key);\n  if (!prev || rank(nf) > rank(prev)) {\n    nf.dedupKey = key;\n    best.set(key, nf);\n  }\n}\n\nconst unique = Array.from(best.values()).sort((a,b) => rank(b) - rank(a));\n\n// Output items\nreturn unique.map(f => ({ json: f }));"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1600,
        0
      ],
      "id": "044cba8a-551b-44a6-b7a1-3c1f7a805a06",
      "name": "Collect Normalize Dedup"
    },
    {
      "parameters": {
        "batchSize": 1,
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        1800,
        0
      ],
      "id": "caf71b89-0509-40cc-9220-576f40c3096c",
      "name": "Loop Findings"
    },
    {
      "parameters": {
        "amount": 200,
        "unit": "milliseconds"
      },
      "type": "n8n-nodes-base.wait",
      "typeVersion": 1,
      "position": [
        2000,
        0
      ],
      "id": "7f2bb79d-3225-4741-9c9e-cf80c68044d4",
      "name": "Rate Limit"
    },
    {
      "parameters": {
        "jsCode": "// Build a deterministic instruction for the reporter agent to call MCP report tool exactly once.\nconst f = $json || {};\nconst type = String(f.type || 'unknown');\nconst reason = String(f.reason || '').trim() || `${type} hit`;\nconst score = (typeof f.score === 'number' ? f.score : parseInt(f.score, 10)) || 5;\n\nlet trace = [];\nif (Array.isArray(f.trace)) {\n  trace = f.trace.map(x => ({\n    class: String(x.class ?? '').replace(/\\//g,'.'),\n    method: String(x.method ?? ''),\n    desc: String(x.desc ?? ''),\n  }));\n}\nif (!trace.length) trace = [{class:'', method:'', desc:''}];\n\nconst payload = { type, reason, score, trace };\n\nconst chatInput = `请使用工具 report 上报以下漏洞。必须只调用一次 report 工具并传入完整 JSON；调用后只输出 {\"ok\":true}。\nreport 参数 JSON：\n${JSON.stringify(payload, null, 2)}\n`;\n\nreturn [{ json: { ...f, callLimit: 2, chatInput, reportPayload: payload } }];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2200,
        0
      ],
      "id": "50d4525a-963a-40a6-a3c5-fb499813c748",
      "name": "Build Report Prompt"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "options": {
          "systemMessage": "你是漏洞报告机器人。\n必须遵守：\n1) 你必须调用一次且仅一次名为 report 的工具来上报漏洞；参数必须严格使用输入中提供的 JSON（不要更改字段名、不要自作主张补充虚构数据）。\n2) 如果输入缺字段，使用空字符串/默认值，但仍需调用 report。\n3) 工具调用完成后，只输出一个 JSON：{\"ok\":true}。不要输出其他解释。",
          "maxIterations": "={{ $json.callLimit }}"
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 2.2,
      "position": [
        2400,
        0
      ],
      "id": "8d321321-7751-4033-9306-c9cca03fdc28",
      "name": "Reporter Agent",
      "onError": "continueErrorOutput"
    },
    {
      "parameters": {
        "jsCode": "// Workflow finished.\nreturn [{json:{ok:true, message:\"Audit workflow finished\"}}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        2600,
        120
      ],
      "id": "ac5e0a2e-773c-411e-8d9f-87b3750a8631",
      "name": "Done"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.scanConfig.enableGraphLite }}",
              "operation": "isTrue"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        800,
        -240
      ],
      "id": "ece0eccb-1b3b-4036-8f57-776423a62f1a",
      "name": "If Enable graph-lite"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.scanConfig.enableVulRules }}",
              "operation": "isTrue"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        800,
        -60
      ],
      "id": "4e26a641-c86b-4d60-8756-f00403833215",
      "name": "If Enable vul-rules"
    },
    {
      "parameters": {
        "conditions": {
          "boolean": [
            {
              "value1": "={{ $json.scanConfig.enableScaLeak }}",
              "operation": "isTrue"
            }
          ]
        }
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        800,
        90
      ],
      "id": "fb4eb595-6223-4cec-b5c5-009f1a21c465",
      "name": "If Enable sca-leak"
    },
    {
      "parameters": {
        "jsCode": "// graph-lite disabled: return empty findings placeholder so merge can proceed.\nreturn [{\n  json: {\n    line: \"graph-lite\",\n    parseOk: true,\n    parseError: \"disabled\",\n    findings: []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1000,
        -60
      ],
      "id": "f54f7e98-271f-4983-8bad-14ea55332977",
      "name": "Graph-lite Disabled"
    },
    {
      "parameters": {
        "jsCode": "// vul-rules disabled: return empty findings placeholder so merge can proceed.\nreturn [{\n  json: {\n    line: \"vul-rules\",\n    parseOk: true,\n    parseError: \"disabled\",\n    findings: []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1000,
        120
      ],
      "id": "3dd91637-33da-4d65-807f-bc9ed3bccece",
      "name": "Vul-rules Disabled"
    },
    {
      "parameters": {
        "jsCode": "// sca-leak disabled: return empty findings placeholder so merge can proceed.\nreturn [{\n  json: {\n    line: \"sca-leak\",\n    parseOk: true,\n    parseError: \"disabled\",\n    findings: []\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1000,
        300
      ],
      "id": "a1471cec-dcad-4937-86c4-4ee6d4719aea",
      "name": "Sca-leak Disabled"
    }
  ],
  "connections": {
    "Start Workflow": {
      "main": [
        [
          {
            "node": "Global Constants",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Global Constants": {
      "main": [
        [
          {
            "node": "Get Jars List",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Get Jars List": {
      "main": [
        [
          {
            "node": "Init Scan Config",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Init Scan Config": {
      "main": [
        [
          {
            "node": "Build Prompt audit-fast",
            "type": "main",
            "index": 0
          },
          {
            "node": "If Enable dfs-taint",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "If Enable graph-lite",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "If Enable vul-rules",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "If Enable sca-leak",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Prompt audit-fast": {
      "main": [
        [
          {
            "node": "Agent audit-fast",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent audit-fast": {
      "main": [
        [
          {
            "node": "Parse audit-fast",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse audit-fast": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Prompt graph-lite": {
      "main": [
        [
          {
            "node": "Agent graph-lite",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent graph-lite": {
      "main": [
        [
          {
            "node": "Parse graph-lite",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse graph-lite": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Build Prompt vul-rules": {
      "main": [
        [
          {
            "node": "Agent vul-rules",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent vul-rules": {
      "main": [
        [
          {
            "node": "Parse vul-rules",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse vul-rules": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Build Prompt sca-leak": {
      "main": [
        [
          {
            "node": "Agent sca-leak",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent sca-leak": {
      "main": [
        [
          {
            "node": "Parse sca-leak",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse sca-leak": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 3
          }
        ]
      ]
    },
    "If Enable dfs-taint": {
      "main": [
        [
          {
            "node": "Build Prompt dfs-taint",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "DFS Disabled",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Prompt dfs-taint": {
      "main": [
        [
          {
            "node": "Agent dfs-taint",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Agent dfs-taint": {
      "main": [
        [
          {
            "node": "Parse dfs-taint",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse dfs-taint": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 4
          }
        ]
      ]
    },
    "DFS Disabled": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 4
          }
        ]
      ]
    },
    "Merge Lines": {
      "main": [
        [
          {
            "node": "Collect Normalize Dedup",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Collect Normalize Dedup": {
      "main": [
        [
          {
            "node": "Loop Findings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Findings": {
      "main": [
        [
          {
            "node": "Rate Limit",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Done",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Rate Limit": {
      "main": [
        [
          {
            "node": "Build Report Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Report Prompt": {
      "main": [
        [
          {
            "node": "Reporter Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Reporter Agent": {
      "main": [
        [
          {
            "node": "Loop Findings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "LLM": {
      "ai_languageModel": [
        [
          {
            "node": "Agent audit-fast",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Agent graph-lite",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Agent vul-rules",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Agent sca-leak",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Agent dfs-taint",
            "type": "ai_languageModel",
            "index": 0
          },
          {
            "node": "Reporter Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "MCP audit-fast": {
      "ai_tool": [
        [
          {
            "node": "Agent audit-fast",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP graph-lite": {
      "ai_tool": [
        [
          {
            "node": "Agent graph-lite",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP vul-rules": {
      "ai_tool": [
        [
          {
            "node": "Agent vul-rules",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP sca-leak": {
      "ai_tool": [
        [
          {
            "node": "Agent sca-leak",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP dfs-taint": {
      "ai_tool": [
        [
          {
            "node": "Agent dfs-taint",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "MCP report": {
      "ai_tool": [
        [
          {
            "node": "Reporter Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "If Enable graph-lite": {
      "main": [
        [
          {
            "node": "Build Prompt graph-lite",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Graph-lite Disabled",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Enable vul-rules": {
      "main": [
        [
          {
            "node": "Build Prompt vul-rules",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Vul-rules Disabled",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "If Enable sca-leak": {
      "main": [
        [
          {
            "node": "Build Prompt sca-leak",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Sca-leak Disabled",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Graph-lite Disabled": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 1
          }
        ]
      ]
    },
    "Vul-rules Disabled": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 2
          }
        ]
      ]
    },
    "Sca-leak Disabled": {
      "main": [
        [
          {
            "node": "Merge Lines",
            "type": "main",
            "index": 3
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "4de75b24-4d83-4254-b498-c690ea0f26ca",
  "meta": {
    "instanceId": "REPLACE_WITH_YOUR_INSTANCE_ID"
  },
  "id": "REPLACE_WITH_YOUR_WORKFLOW_ID",
  "tags": [],
  "pinData": {}
}